% Methodology chapter aligned with Delivery 3 baseline (long version)
\chapter{Methodology}
\label{ch:method}

This chapter details the methodology used to design the air quality monitoring platform for Bogotá with a focus on the Delivery 3 baseline. The baseline centers on PostgreSQL as the primary data store, periodic ingestion (e.g., every 10 minutes), a normalized schema up to Third Normal Form (3NF), indexing and partitioning strategies for analytical queries, a REST API, and a rule-based recommendation subsystem. Technologies such as TimescaleDB hypertables, MinIO object storage, full NoSQL ingestion pipelines, and GraphQL are considered future work and are not required in the baseline.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Objectives}
\label{sec:method_objectives}

The methodology pursues the following objectives:
\begin{enumerate}
  \item Provide a normalized relational schema on PostgreSQL for stations, pollutants, and time-series readings.
  \item Implement a periodic ingestion pipeline (baseline: 10-minute polling) to validate, normalize, and persist observations reliably.
  \item Define index and partition strategies that support the platform’s key analytics and dashboard queries with predictable latency.
  \item Deliver a simple, rule-based recommendation mechanism for alerts and informational guidance.
  \item Specify a reproducible performance validation plan that can be executed in future iterations (JMeter scenarios, EXPLAIN/ANALYZE checks, and basic monitoring).
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scope}
\label{sec:method_scope}

The scope of this deliverable includes a single-city deployment (Bogotá), ingestion of selected historical and current datasets, and a web-based interface consuming REST endpoints. The baseline focuses on:
\begin{itemize}
  \item PostgreSQL as the core datastore with declarative temporal partitioning (by month) for the main readings table.
  \item A normalized schema (to 3NF) for canonical entities and relationships.
  \item Indexing and materialized views targeting common analytical and dashboard queries.
  \item A rule-based alerting and recommendation subsystem based on measured AQI thresholds.
\end{itemize}

Out of scope for the baseline: strict real-time ingestion, production-grade multi-region replication, GraphQL, full object storage for raw payloads, and machine-learning-based recommendations. These are documented as potential enhancements.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Assumptions}
\label{sec:method_assumptions}

The following assumptions guided the design:
\begin{itemize}
  \item Provider payloads expose station identifiers and timestamps that can be normalized to UTC.
  \item A 10-minute polling interval is representative of provider update cadence and dashboard requirements.
  \item A modest single-node database host (e.g., 4 vCPU, 16 GB RAM) is available for baseline testing.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations}
\label{sec:method_limitations}

The baseline does not implement strict real-time ingestion, automatic failover, or multi-region replication. Recommendations are informative and not clinically validated. External API quotas and data quality may affect completeness and timeliness of ingested data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Database Design Methodology}
\label{subsec:method_dbdesign}

The database design followed an iterative process with conceptual, logical, and physical phases. The primary entities include stations, pollutants, providers, users (for preferences/alerts), and the canonical readings table.

\subsubsection{Conceptual Modeling}
The conceptual model represents real-world concepts: \textbf{Station}, \textbf{Pollutant}, \textbf{Provider}, \textbf{AirQualityReading}, and user-related entities (preferences/alerts). Relationships capture measurements per station and pollutant over time, with provider traceability.

\subsubsection{Logical Modeling}
The logical schema targets PostgreSQL and adheres to 3NF where practical:
\begin{itemize}
  \item \textbf{Core readings table:} \texttt{airquality\_reading} with foreign keys to \texttt{station}, \texttt{pollutant}, and \texttt{provider}.
  \item \textbf{Uniqueness:} a unique constraint on (\texttt{station\_id}, \texttt{pollutant\_id}, \texttt{datetime}) prevents duplicates from multiple sources.
  \item \textbf{Reference tables:} normalized entities (e.g., \texttt{station}, \texttt{pollutant}, \texttt{provider}) maintain referential integrity and avoid redundancy.
  \item \textbf{User-related data:} user preferences and dashboard configurations can be stored as JSONB in PostgreSQL or in a lightweight NoSQL store when flexibility is needed.
\end{itemize}

\subsubsection{Physical Implementation}
The physical design emphasizes predictable query performance and manageable ingestion throughput:
\begin{itemize}
  \item Declarative temporal partitioning (monthly) for \texttt{airquality\_reading} to limit scan ranges and support retention.
  \item B-tree or BRIN indexes aligned to query patterns (see Section~\ref{subsec:method_indexing}).
  \item Optional materialized views for common rollups (hourly/daily aggregates) refreshed periodically.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Data Ingestion}
\label{subsec:method_ingest}

The ingestion service (Python) performs periodic polling of providers and executes the following steps per cycle:
\begin{enumerate}
  \item Fetch JSON payloads for targeted stations/areas in Bogotá.
  \item Validate the payloads (schema presence, timestamps parsable), normalize to the canonical schema and UTC.
  \item Deduplicate and upsert into the partitioned \texttt{airquality\_reading} table using the uniqueness constraint.
  \item Emit logs and basic metrics for observability. Raw payload persistence to object storage is considered future work.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Normalization and Storage}
\label{subsec:method_normalization}

Normalization ensures consistent semantics across sources:
\begin{itemize}
  \item Field mapping from provider-specific names (e.g., \texttt{pm25}, \texttt{PM2\_5}) to canonical columns (e.g., \texttt{pm25}).
  \item Unit harmonization (e.g., to $\mu$g/m$^{3}$) and value-range validation.
  \item UTC-timestamp normalization and enforcement of (station, pollutant, datetime) uniqueness during inserts/upserts.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Indexing and Query Optimization}
\label{subsec:method_indexing}

The indexing strategy derives from common filtering/grouping patterns. All indexes should be validated with \texttt{EXPLAIN} and \texttt{EXPLAIN ANALYZE} on representative data.

\paragraph{Recent measurements per station}
\begin{verbatim}
SELECT *
FROM airquality_reading
WHERE station_id = $1
  AND datetime >= NOW() - INTERVAL '24 hours';
\end{verbatim}
Recommended index:
\begin{verbatim}
CREATE INDEX idx_reading_station_time
ON airquality_reading (station_id, datetime DESC);
\end{verbatim}

\paragraph{Daily pollutant averages per city}
\begin{verbatim}
SELECT city_id, pollutant_id, AVG(aqi_value)
FROM airquality_reading
WHERE datetime BETWEEN $1 AND $2
GROUP BY city_id, pollutant_id;
\end{verbatim}
Recommended index:
\begin{verbatim}
CREATE INDEX idx_reading_city_pollutant_time
ON airquality_reading (city_id, pollutant_id, datetime);
\end{verbatim}

\paragraph{Time-series trend for one pollutant}
\begin{verbatim}
SELECT datetime, aqi_value
FROM airquality_reading
WHERE pollutant_id = $1 AND station_id = $2
ORDER BY datetime;
\end{verbatim}
Recommended index:
\begin{verbatim}
CREATE INDEX idx_reading_pollutant_station_time
ON airquality_reading (pollutant_id, station_id, datetime);
\end{verbatim}

\paragraph{Partial index for recent data}
\begin{verbatim}
CREATE INDEX idx_reading_recent
ON airquality_reading (datetime)
WHERE datetime >= NOW() - INTERVAL '30 days';
\end{verbatim}

\paragraph{BRIN index for long-term historical scans}
\begin{verbatim}
CREATE INDEX idx_reading_brin
ON airquality_reading USING BRIN (datetime);
\end{verbatim}

Beyond indexing, query optimization techniques include:
\begin{itemize}
  \item Using declarative partitioning to reduce scan ranges.
  \item Employing materialized views for expensive rollups with periodic refreshes.
  \item Simplifying queries to align predicates and sort orders with indexes.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Concurrency Analysis}
\label{subsec:method_concurrency}

The system balances periodic writes with read-heavy analytical workloads:
\begin{itemize}
  \item Short ingestion transactions and index-aligned queries reduce lock durations under MVCC.
  \item Temporal partitioning isolates writes on recent partitions from historical scans.
  \item Maintenance (VACUUM, ANALYZE, materialized view refresh) should be scheduled during low-traffic windows.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{API Layer and Services}
\label{subsec:method_api}

The baseline exposes REST endpoints supporting pagination and time-window filters for stations, readings, and aggregates. Authentication/authorization and rate limiting are considered production enhancements.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Recommendation Engine}
\label{subsec:method_recommendation}

The recommendation subsystem is rule-based. Rules map recent AQI/pollutant thresholds and user preferences (e.g., activity level) to deterministic messages. Rules can be implemented in SQL or application logic and should include identifiers for explainability.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Performance Validation and Experiments}
\label{subsec:method_performance}

The validation plan includes: ingesting historical data to observe throughput and storage growth; capturing \texttt{EXPLAIN ANALYZE} for representative queries; and optionally running JMeter scenarios to simulate concurrent dashboards. Empirical results are planned for future iterations; no production-scale benchmarks are claimed in this deliverable.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary of Methodology}
\label{sec:method_summary}

This chapter presented the Delivery 3 methodology: PostgreSQL-centered design, periodic ingestion, normalized schema (to 3NF), indexes and partitioning aligned to core queries, a REST API, and a rule-based recommendation engine. Future work includes object storage for raw payloads, TimescaleDB features, GraphQL, and production-grade HA/DR.
