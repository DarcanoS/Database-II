\chapter{Literature Review}
\label{ch:lit_rev}

This chapter reviews the existing literature and technological solutions related to air quality monitoring systems, time-series database architectures, real-time data processing frameworks, and personalized recommendation engines. The review establishes the theoretical foundation for the system design choices presented in Chapter~\ref{ch:method} and positions this project within the broader context of environmental health informatics and database systems research.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Air Quality Monitoring: A Public Health Imperative}
\label{sec:lit_aq_health}

Air pollution represents one of the most significant environmental health challenges of the 21st century. According to the World Health Organization, ambient and household air pollution jointly cause an estimated seven to eight million premature deaths annually, with 99\% of the global population exposed to air that exceeds WHO guideline values~\citep{whopollution}. The 2024 State of Global Air report identifies PM$_{2.5}$ (particulate matter with diameter less than 2.5 micrometers) exposure as the second leading risk factor for mortality worldwide, surpassing well-known factors such as high blood pressure and tobacco smoking~\citep{state}.

\subsection{Air Quality in Latin American Megacities}
\label{subsec:lit_latam}

Latin American urban centers face particularly acute air quality challenges due to rapid urbanization, vehicular emissions, industrial activities, and geographic conditions that trap pollutants. Bogotá, Colombia's capital and the focus of this project, has shown spatially heterogeneous PM$_{2.5}$ concentrations despite gradual improvements. Studies document a decline from 15.7~$\mu$g/m$^3$ in 2017 to 13.1~$\mu$g/m$^3$ in 2019, driven in part by the city's Air Plan 2030 initiative. However, these levels still exceed WHO recommended limits, and significant hot spots persist in industrial and high-traffic zones.

The public health implications extend beyond mortality statistics. Chronic exposure to elevated PM$_{2.5}$ levels correlates with increased incidence of respiratory diseases, cardiovascular conditions, and adverse pregnancy outcomes. Vulnerable populations—including children, elderly individuals, and those with pre-existing respiratory conditions—face disproportionate risks. These findings underscore the critical need for continuous, fine-grained monitoring combined with citizen-oriented decision support systems that translate technical air quality metrics into actionable health guidance.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Existing Air Quality Data Platforms}
\label{sec:lit_platforms}

Multiple platforms provide real-time and historical air quality data through public APIs and web interfaces. Understanding their capabilities and limitations informed the design decisions for this project's data integration strategy.

\subsection{AQICN (Air Quality Index China Network)}
\label{subsec:lit_aqicn}

AQICN offers one of the most comprehensive global air quality databases, providing minute-level Air Quality Index (AQI) readings and historical archives for over 100 countries~\citep{aqicn}. The platform aggregates data from government monitoring stations, low-cost sensor networks, and satellite observations. Historical data is available in CSV format dating back to 2015, making it valuable for retrospective analyses and baseline establishment.

However, AQICN presents data primarily as raw numerical values without personalization or contextual health guidance. Users must independently interpret AQI values and understand the implications for their specific health conditions and planned activities. The platform's strength lies in comprehensive spatial and temporal coverage rather than user-oriented decision support.

\subsection{Google Air Quality API}
\label{subsec:lit_google}

Google's Air Quality API provides high-resolution (500-meter grid) air quality indices combined with pollutant-specific concentrations and basic health recommendations~\citep{google}. The API returns structured JSON responses that include current conditions, hourly forecasts, and general health tips categorized by activity type (e.g., outdoor exercise, commuting).

While Google's service offers superior spatial granularity and more accessible health messaging compared to AQICN, it enforces strict quota limits that complicate city-scale analytics and continuous monitoring applications. Free-tier usage allows only limited requests per day, and high-volume access requires enterprise agreements. Additionally, the service focuses primarily on current and short-term forecast data, with limited support for long-term historical analysis.

\subsection{IQAir AirVisual}
\label{subsec:lit_iqair}

IQAir operates a global network of calibrated air quality sensors and provides data through both consumer applications and a REST API~\citep{iqairapi}. The platform emphasizes sensor accuracy and calibration protocols, offering reliability superior to many low-cost sensor networks. Data is available at hourly aggregation intervals with real-time updates for major metropolitan areas.

IQAir's business model includes tiered pricing for API access, with free tiers limited to basic functionality and higher-volume data retrieval requiring paid subscriptions. This pricing structure presents barriers for research projects and non-commercial applications requiring comprehensive historical data access. Furthermore, hourly aggregation may be insufficient for applications requiring finer temporal granularity to capture rapid pollution events.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Time-Series Database Technologies}
\label{sec:lit_tsdb}

Air quality monitoring generates inherently time-series data characterized by regular temporal sampling, append-heavy write patterns, and queries focused on temporal ranges and aggregations. Traditional relational databases can struggle with the scale and performance requirements of high-frequency environmental monitoring. This section reviews specialized time-series database technologies and extensions that address these challenges.

\subsection{PostgreSQL and Relational Foundations}
\label{subsec:lit_postgresql}

PostgreSQL provides a robust, ACID-compliant relational database foundation with extensive support for complex queries, foreign key constraints, and transactional integrity~\citep{postgresql}. Its extensibility through custom data types, functions, and extensions makes it particularly suitable for hybrid workloads combining structured relational data (users, stations, permissions) with time-series measurements.

Native PostgreSQL features relevant to time-series workloads include declarative table partitioning (introduced in PostgreSQL 10 and enhanced in subsequent versions), which enables horizontal splitting of large tables based on time ranges. Monthly or yearly partitions allow the query planner to prune irrelevant data, significantly reducing I/O for time-bounded queries. PostgreSQL's MVCC (Multi-Version Concurrency Control) architecture provides non-blocking reads during concurrent write operations, essential for systems ingesting data continuously while serving user queries.

\subsection{TimescaleDB: Time-Series Extension}
\label{subsec:lit_timescaledb}

TimescaleDB is a widely used PostgreSQL extension that offers specialized time-series optimizations; it is considered in this review as a possible enhancement for production deployments, but it is not a mandatory component of the baseline prototype. TimescaleDB extends PostgreSQL with features that simplify time-series management while maintaining SQL compatibility and leveraging PostgreSQL's ecosystem~\citep{timescale}. The core abstraction is the \textit{hypertable}, which automatically partitions data across multiple chunks based on time intervals while presenting a unified table interface to applications.

Key features relevant to air quality monitoring include:

\begin{itemize}
    \item \textbf{Automatic chunk management}: TimescaleDB creates and manages time-based chunks transparently, optimizing chunk size based on ingestion patterns and query characteristics.
    \item \textbf{Compression}: Columnar compression algorithms specialized for time-series data can reduce storage requirements by 90\% or more while maintaining query performance through selective decompression.
    \item \textbf{Continuous aggregates}: Materialized views automatically maintained by TimescaleDB that incrementally update as new data arrives, eliminating the need for full table scans to compute aggregations.
    \item \textbf{Data retention policies}: Automated mechanisms to expire old data based on configurable time windows, simplifying compliance with data retention requirements.
\end{itemize}

TimescaleDB's design philosophy prioritizes PostgreSQL compatibility, ensuring that existing PostgreSQL tools, connectors, and expertise remain applicable. This compatibility reduces operational complexity compared to standalone time-series databases that require separate infrastructure and skill sets.

\subsection{Alternative Time-Series Databases}
\label{subsec:lit_alternatives}

For the prototype we adopt PostgreSQL as the baseline relational engine; TimescaleDB is discussed as a complementary option for future scaling. Understanding alternative time-series databases provides context for this decision:

\textbf{InfluxDB} specializes exclusively in time-series data with a custom query language (InfluxQL/Flux) and a schema-less tag-value data model~\citep{influxdb}. It excels at high-ingestion-rate scenarios but sacrifices relational capabilities and ACID guarantees, making it less suitable for applications requiring complex joins across relational entities (users, permissions, recommendations).

\textbf{Apache Cassandra} offers extreme horizontal scalability through a distributed architecture but requires accepting eventual consistency and limited query flexibility~\citep{cassandra}. The operational complexity of managing multi-node Cassandra clusters exceeds the requirements of a single-city deployment focused on Bogotá.

\textbf{Prometheus} targets metrics collection and monitoring use cases with excellent support for dimensional data and alerting but lacks general-purpose query capabilities and long-term storage optimization~\citep{prometheus}. Its design assumes metrics retention measured in weeks rather than years of historical data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Real-Time Data Processing and Stream Analytics}
\label{sec:lit_streaming}

Environmental monitoring systems must process continuous data streams from multiple sources while maintaining low latency for user-facing applications. This section reviews architectural patterns and technologies for real-time data processing.

\subsection{Batch vs. Stream Processing Paradigms}
\label{subsec:lit_paradigms}

Traditional batch processing systems collect data over time windows (hours or days) before processing, introducing inherent latency incompatible with real-time monitoring requirements. Stream processing architectures, in contrast, treat data as unbounded sequences of events processed incrementally as they arrive~\citep{wiley}.

The Lambda Architecture, proposed by Nathan Marz, attempts to combine batch and stream processing: a batch layer provides comprehensive, eventually-consistent views while a speed layer handles real-time updates~\citep{mdpi}. However, this architecture introduces operational complexity through dual code paths and reconciliation logic. Modern approaches favor the Kappa Architecture, which unifies batch and stream processing through a single code path operating on event logs~\citep{medium}.

\subsection{Stream Processing Frameworks}
\label{subsec:lit_frameworks}

\textbf{Apache Kafka} provides distributed, fault-tolerant event streaming with durable message logs, high throughput, and horizontal scalability~\citep{medium}. Kafka's log-based architecture enables replay of historical events and supports multiple consumer groups reading at different rates. For air quality monitoring, Kafka could decouple data ingestion from database writes, buffering during peak loads and enabling independent scaling of producers and consumers.

\textbf{Apache Flink} offers stateful stream processing with exactly-once semantics and low-latency event-time processing~\citep{esr}. Flink excels at complex event processing, windowed aggregations, and pattern detection. Recent case studies demonstrate Kafka-Flink pipelines achieving sub-second end-to-end latency in ESG monitoring and smart city applications, validating the architecture for environmental use cases.

\textbf{Apache Spark Structured Streaming} extends Spark's batch processing API with micro-batch streaming semantics~\citep{medium}. While introducing slightly higher latency compared to Flink, Spark provides a unified API for batch and streaming workloads, simplifying analytics pipelines that combine real-time and historical data.

For this project's initial scope—ten-minute ingestion intervals and a single-city deployment—full-scale stream processing frameworks introduce unnecessary complexity. The simpler Python-based polling architecture with direct database writes proves sufficient. However, understanding these frameworks informs future expansion to higher-frequency ingestion or multi-city deployments.

\subsection{Object Storage for Raw Data Preservation}
\label{subsec:lit_object_storage}

Modern data architectures increasingly adopt the pattern of preserving raw data in immutable object storage before transformation~\citep{minio}. This approach provides several benefits:

\begin{itemize}
    \item \textbf{Auditability}: Original API responses remain available for verification and compliance purposes.
    \item \textbf{Reprocessing capability}: Schema evolution or bug fixes in normalization logic can be applied retroactively to historical data.
    \item \textbf{Cost efficiency}: Object storage (e.g., MinIO, Amazon S3, Azure Blob Storage) offers lower cost-per-gigabyte compared to database storage.
    \item \textbf{Separation of concerns}: Decoupling raw data preservation from normalized data access simplifies each component.
\end{itemize}

\textbf{MinIO} provides an open-source, S3-compatible object storage system deployable on-premises or in cloud environments~\citep{minio}. Its versioning capabilities enable tracking changes to objects over time, supporting regulatory requirements and enabling rollback scenarios.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Query Optimization and Materialized Views}
\label{sec:lit_query_opt}

Real-time dashboards and analytics require sub-second query response times even when operating over millions of historical records. This section reviews database optimization techniques that enable high-performance data access.

\subsection{Materialized Views}
\label{subsec:lit_matviews}

Materialized views store the results of complex queries as physical tables, trading storage space and refresh overhead for dramatically improved read performance~\citep{postgsmv}. Unlike standard views that recompute results on each access, materialized views can serve queries directly from pre-computed data.

PostgreSQL's \texttt{REFRESH MATERIALIZED VIEW CONCURRENTLY} command enables view updates without blocking concurrent read queries, eliminating the availability gaps that plague traditional materialized views requiring exclusive locks. This capability proves essential for applications requiring continuous data access during refresh operations. The concurrent refresh mechanism maintains a second copy of the view, updates it in place, and atomically swaps pointers once the refresh completes.

\subsection{Indexing Strategies}
\label{subsec:lit_indexing}

Effective indexing dramatically reduces query execution time by minimizing table scans. For time-series workloads, several indexing strategies prove valuable:

\begin{itemize}
    \item \textbf{B-tree indexes} on timestamp columns enable efficient range queries and time-bounded scans, the most common access pattern for historical data.
    \item \textbf{Composite indexes} combining timestamp, station, and pollutant columns support queries filtering on multiple dimensions without requiring index intersection.
    \item \textbf{Partial indexes} covering only recent data (e.g., last 30 days) reduce index size and maintenance overhead while maintaining performance for the most frequent queries.
    \item \textbf{BRIN (Block Range INdexes)} provide space-efficient indexing for naturally ordered data, trading exact positioning for dramatically reduced index size—particularly effective for append-only time-series tables.
\end{itemize}

\subsection{Query Planning and Execution}
\label{subsec:lit_query_plan}

PostgreSQL's cost-based query optimizer selects execution plans by estimating I/O costs, CPU overhead, and memory requirements for alternative strategies. For time-series queries, several factors influence performance:

\textbf{Partition pruning} eliminates scanning of irrelevant partitions based on query predicates. A query requesting data from January 2024 can skip all partitions outside that month, reducing search space by orders of magnitude.

\textbf{Parallel query execution} distributes query work across multiple CPU cores, particularly effective for aggregations over large datasets. PostgreSQL's parallel sequential scan and parallel aggregate capabilities can reduce query time linearly with available cores for certain query patterns.

\textbf{Query result caching} at the application layer complements database-level optimizations by serving frequently requested results from memory without database round-trips. Redis and Memcached provide popular caching solutions, though careful cache invalidation logic must ensure data freshness.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Recommendation Systems and Personalization}
\label{sec:lit_reco}

Translating raw environmental data into personalized health guidance requires recommendation systems that consider user context, health profiles, and activity patterns.

\subsection{Content-Based Filtering}
\label{subsec:lit_content}

Content-based recommendation systems suggest items based on their attributes and user preferences~\citep{epaaqi}. For air quality applications, this translates to matching pollutant levels and AQI categories against user-defined thresholds, health conditions, and planned activities.

The EPA's Air Quality Index provides a standardized framework for categorizing pollution levels: Good (0-50), Moderate (51-100), Unhealthy for Sensitive Groups (101-150), Unhealthy (151-200), Very Unhealthy (201-300), and Hazardous (>300)~\citep{epaaqi}. Each category maps to health guidance for different population segments. Content-based filtering applies these mappings to individual users based on their risk profiles (e.g., respiratory conditions, age, pregnancy status).

\subsection{Rule-Based Recommendation Engines}
\label{subsec:lit_rules}

While collaborative filtering and machine learning approaches excel at discovering patterns in user behavior, rule-based systems prove more appropriate for health guidance where recommendations must be explainable and compliant with established medical guidelines~\citep{whoaq}.

WHO air quality guidelines specify recommended exposure limits for key pollutants: PM$_{2.5}$ annual mean of 5 $\mu$g/m$^3$, PM$_{10}$ annual mean of 15 $\mu$g/m$^3$, O$_3$ peak season mean of 60 $\mu$g/m$^3$~\citep{whoaq}. Rule-based systems encode these thresholds alongside activity-specific guidance (e.g., "Avoid outdoor exercise when PM$_{2.5}$ > 35 $\mu$g/m$^3$").

The deterministic nature of rule-based recommendations provides transparency critical for health applications: users can understand why specific advice was generated and verify recommendations against source guidelines. This explainability surpasses black-box machine learning models where recommendation rationale remains opaque.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work and Existing Systems}
\label{sec:lit_related}

Several research projects and commercial systems address aspects of air quality monitoring and citizen engagement, each with distinct approaches and limitations that inform this project's design.

Low-cost sensor networks expand spatial coverage beyond government monitoring stations but introduce data quality challenges requiring calibration and validation protocols~\citep{wiley}. Projects deploying hundreds of sensors across urban areas demonstrate the feasibility of fine-grained pollution mapping but often lack integrated data platforms connecting sensors to citizen-facing applications.

Smart city initiatives increasingly incorporate air quality monitoring as a component of broader urban environmental management~\citep{mdpi}. These systems typically focus on data collection and visualization for municipal planning rather than personalized citizen guidance. Integration with other urban data streams (traffic, weather, public health) remains an active research area.

Commercial platforms like PurpleAir and Breezometer provide consumer-oriented air quality information with mobile applications and API access. However, these proprietary systems limit academic research and customization, and their recommendation algorithms remain undocumented black boxes.

Academic research on environmental health informatics has explored machine learning for pollution forecasting, exposure estimation, and health impact prediction~\citep{esr}. While these predictive models show promise, operational deployment requires integration with reliable data infrastructure and user-facing applications—the focus of this project.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
\label{sec:lit_summary}

This literature review establishes the foundation for the air quality monitoring platform developed in this project. Key findings include:

\begin{enumerate}
    \item Air pollution represents a critical public health challenge, particularly in Latin American megacities like Bogotá, requiring continuous monitoring and citizen-oriented decision support.
    
    \item Existing air quality data platforms (AQICN, Google Air Quality API, IQAir) provide valuable data sources but lack integration, personalization, and accessible health guidance, creating the need for a unified platform.
    
    \item PostgreSQL provides a strong baseline for relational integrity and analytical workloads; time-series extensions such as TimescaleDB are presented as optional enhancements that can simplify chunk management and continuous aggregates when scaling beyond the prototype.
    
    \item Modern stream processing frameworks (Kafka, Flink, Spark) enable sophisticated real-time analytics but introduce complexity unnecessary for ten-minute ingestion intervals; simpler polling architectures prove sufficient for initial deployment while maintaining upgrade paths to streaming if requirements evolve.
    
    \item Object storage patterns (MinIO) for raw data preservation enable auditability, reprocessing, and cost efficiency while decoupling ingestion from processing concerns.
    
    \item Materialized views with concurrent refresh capabilities provide the query acceleration necessary for real-time dashboards without introducing availability gaps during refresh operations.
    
    \item Rule-based recommendation systems offer transparency and compliance with health guidelines essential for medical advice applications, surpassing machine learning approaches where explainability matters more than pattern discovery.
\end{enumerate}

The following chapter describes how these technologies and patterns integrate into a cohesive system architecture addressing the requirements identified in Chapter~\ref{ch:into}.

The literature above guided specific design choices for Chapter~\ref{ch:method}: we selected a PostgreSQL-centered baseline to preserve ACID semantics and relational modeling for entities (stations, users, recommendations); declarative temporal partitioning and targeted indexes to enable efficient time-bounded queries; materialized views and selective refresh strategies to accelerate common aggregations; a lightweight NoSQL store for user preferences and dashboard configuration (separating small mutable objects from bulk time-series data); a periodic polling ingestion pattern (e.g., 10-minute cycles) as a pragmatic initial approach instead of a full stream-processing pipeline; and rule-based recommendation logic to guarantee explainability and alignment with health guidelines. These choices prioritize reproducibility and operational simplicity while leaving clear upgrade paths (object storage, time-series extensions, streaming frameworks) for future work.
