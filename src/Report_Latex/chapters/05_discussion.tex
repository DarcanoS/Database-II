\chapter{Discussion and Analysis}
\label{ch:evaluation}

This chapter interprets the planned architecture and expected performance metrics presented in Chapter~\ref{ch:results}, discusses their significance relative to the project objectives, and identifies key limitations and areas for future improvement.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Architectural Design Decisions}
\label{sec:architecture_discussion}

The selection of a PostgreSQL engine extended with TimescaleDB was guided by a balance between operational simplicity, analytical performance, and the functional requirements of a real-time environmental monitoring system. PostgreSQL provides a robust relational foundation for transactional integrity, geospatial processing, and structured domain entities, while TimescaleDB adds purpose-built optimizations for high-volume time-series ingestion and temporal analytics. This hybrid model offers a unified environment capable of supporting both OLTP-style interactions (user management, alerts, system metadata) and OLAP-style time-series exploration without the overhead of managing heterogeneous database engines.

\subsection*{Rationale for Choosing PostgreSQL + TimescaleDB}

PostgreSQL was selected as the primary relational core due to its maturity, ACID compliance, and extensive ecosystem of extensions, including PostGIS for geospatial operations. TimescaleDB introduces hypertables, automatic chunking, and continuous aggregates, which are particularly well suited for periodic air-quality measurements ingested every 10 minutes. These features eliminate the need for manual partition management and support efficient analytical queries over long-term historical datasets. Compared to distributed stream-processing frameworks (Kafka, Flink, Spark), this architecture reduces operational complexity while remaining fully capable of meeting projected ingestion and query demands for the single-city Bogotá deployment.

\textbf{Additional advantages include:}
\begin{itemize}
    \item \textbf{SQL familiarity}: Researchers and engineers can work with standard SQL across both relational and time-series domains, lowering the adoption barrier.
    \item \textbf{Operational simplicity}: A single-node architecture (optionally extended with read replicas) avoids the coordination challenges inherent to distributed consensus systems and multi-broker pipelines.
    \item \textbf{Cost efficiency}: The solution relies entirely on open-source technologies, allowing flexible deployment in cloud or on-premises environments with minimal licensing overhead.
    \item \textbf{Time-series optimization}: TimescaleDB provides native time-based partitioning, compression, retention policies, and continuous aggregates.
\end{itemize}

\subsection*{Table, Relationship, and Partitioning Design}

The schema design followed a hybrid relational--time-series approach:

\begin{itemize}
    \item \textbf{Core relational tables} store users, alert configurations, station metadata, pollutant definitions, API sources, and system logs. These relationships were normalized to Third Normal Form (3NF) to ensure data consistency and reduce redundancy.
    \item \textbf{Time-series hypertables} store raw and processed air-quality measurements. Hypertables were partitioned on a monthly time interval, balancing query performance with manageable chunk sizes.
    \item \textbf{Materialized relationships} such as station-to-city mappings and pollutant classification tables support efficient joins from the relational layer into the time-series domain.
    \item \textbf{Continuous aggregates} were defined for common analytical queries (e.g., hourly averages, daily maximums), reducing query load on the raw measurement table.
\end{itemize}

This structure allows ingestion, storage, and analytical processing to operate without contention, while ensuring that long-term historical data remains query-efficient.

\subsection*{Geographical Storage and Raw Layer Decisions}

Because air-quality data is inherently spatial, the platform incorporates PostGIS to support geographic indexing, distance calculations, polygon intersection queries, and spatial clustering algorithms. Storing stations, regions, and administrative boundaries as geospatial objects allows the system to answer spatial queries such as nearest-station lookup or zone-based pollution alerts.

A raw ingestion layer was introduced to preserve unprocessed API responses before transformation. This layer supports:

\begin{itemize}
    \item reproducibility of experiments,
    \item ingestion auditing,
    \item debugging of anomalous measurements, and
    \item reprocessing pipelines without requiring API re-queries.
\end{itemize}

Raw data is stored in a schemaless JSON column, while normalized and validated readings are inserted into structured time-series tables. This dual-storage approach provides flexibility without sacrificing schema consistency.

\subsection*{Justification for a Hybrid Relational + Time-Series Architecture}

A purely relational model would struggle with the scale and access patterns of high-frequency sensor data, while a pure time-series engine would lack the transactional guarantees and flexible schema needed for the system's broader functionality. The hybrid architecture was therefore chosen to achieve:

\begin{itemize}
    \item \textbf{High-throughput ingestion} optimized by TimescaleDB hypertables.
    \item \textbf{Complex relational joins} necessary for user and alert management.
    \item \textbf{Geospatial processing} enabled by PostGIS extensions.
    \item \textbf{Efficient long-term analytics} through continuous aggregates and compressible chunks.
    \item \textbf{Future extensibility} into distributed or multi-region deployments.
\end{itemize}

This design ensures robustness for the current Bogotá deployment while providing a clear pathway toward horizontal scalability through partitioning, replication, and eventual migration to distributed database backends if multi-city ingestion or sub-minute update cycles become required.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Significance of the Findings}
\label{sec:significance}

The air quality monitoring platform addresses a critical public health need in Bogotá, where PM2.5 concentrations frequently exceed WHO guidelines and contribute to respiratory disease burden. By integrating data from multiple authoritative sources (AQICN, Google Air Quality, IQAir) and providing personalized, explainable health recommendations, the system empowers citizens to make informed decisions about outdoor activities, protective equipment, and exposure risk.

\textbf{Key contributions:}
\begin{itemize}
    \item \textbf{Data integration}: Harmonizing heterogeneous API schemas, pollutant units, and AQI scales into a unified relational model enables consistent cross-source queries and reduces citizen confusion from conflicting air quality reports.
    \item \textbf{Scalability validation}: The planned 1000-concurrent-user load test demonstrates the system's capacity to serve a metropolitan population (Bogotá: $\sim$8 million residents) under realistic dashboard access patterns.
    \item \textbf{Explainable recommendations}: Rule-based health advice mapped from EPA AQI bands provides transparency and traceability, avoiding the "black box" problem of machine learning models while remaining interpretable by non-technical users.
    \item \textbf{Audit and replay}: Raw JSON payloads archived in MinIO enable reprocessing with updated normalization rules, bug fixes, or alternative AQI calculation methods without data loss.
\end{itemize}

The 10-minute recommendation update cycle aligns with WHO guidance that short-term exposure reductions can mitigate acute health effects. Future machine learning extensions (ARIMA, LSTM for PM2.5 forecasting) could enable predictive alerts hours before pollution spikes, further improving health outcomes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Limitations and Challenges}
\label{sec:limitations}

Despite the system's strengths, several limitations affect interpretation and generalization of the results:

\subsection{Data Quality and Sensor Calibration}
External APIs aggregate data from heterogeneous sensor networks, including low-cost sensors that may introduce bias or drift. The platform assumes provider-side calibration and does not implement on-device calibration procedures. Systematic sensor errors could propagate through the normalization pipeline and affect recommendation accuracy.

\textbf{Mitigation strategies:}
\begin{itemize}
    \item Cross-validation: compare readings from multiple co-located sensors and flag outliers.
    \item Reference station anchoring: calibrate low-cost sensors against high-precision government monitoring stations.
    \item Temporal consistency checks: detect and quarantine readings that violate physical plausibility (e.g., negative concentrations, impossible PM2.5 spikes).
\end{itemize}

\subsection{Recommendation Engine Limitations}
The rule-based recommendation engine maps AQI categories to generic health advice templates and does not incorporate individual medical history, pre-existing conditions, or medication interactions. Recommendations should be treated as informational guidance, not clinical directives.

\textbf{Future enhancements:}
\begin{itemize}
    \item Collaboration with public health authorities to validate rule thresholds against local epidemiological data.
    \item Optional user profiles for respiratory conditions (asthma, COPD) to customize sensitivity thresholds.
    \item Integration with electronic health records (subject to privacy regulations) for personalized risk scoring.
\end{itemize}

\subsection{Single-City Deployment Scope}
The current architecture targets Bogotá only and has not been validated for multi-city or international deployments with different AQI standards, regulatory frameworks, or data privacy requirements.

\textbf{Scalability considerations:}
\begin{itemize}
    \item Geographic partitioning by city in addition to temporal partitioning by month.
    \item Regional API endpoints to reduce cross-continent latency for global deployments.
    \item Localization of health recommendations to account for cultural differences in risk perception and communication preferences.
\end{itemize}

\subsection{Performance Assumptions}
The target metrics (NFR1--NFR8) assume a hardware profile of 4 vCPU, 16 GB RAM for the database node. Results may differ on constrained hardware or cloud instances with different I/O characteristics (network-attached storage vs. local NVMe SSDs).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implications for Practice and Research}
\label{sec:implications}

The platform demonstrates that time-series database optimizations (partitioning, continuous aggregates, BRIN indexes) can deliver near-real-time performance for citizen-facing air quality dashboards without requiring distributed stream processing infrastructure. This finding has practical implications for resource-constrained municipalities and environmental agencies seeking to deploy monitoring systems with limited IT budgets and operational expertise.

From a research perspective, the hybrid architecture (batch ingestion + materialized views) provides a foundation for future studies on:
\begin{itemize}
    \item Query optimization techniques for multi-dimensional time-series data (temporal, spatial, pollutant type).
    \item Trade-offs between view materialization strategies (eager vs. lazy refresh, full vs. incremental updates).
    \item Machine learning integration for forecasting and anomaly detection on pre-aggregated historical data.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
\label{sec:discussion_summary}

This chapter discussed the rationale behind key architectural decisions (TimescaleDB vs. distributed streaming), interpreted the significance of expected performance metrics relative to public health goals, and identified limitations related to data quality, recommendation generalizability, and single-city deployment scope. The planned load testing will validate whether the chosen design meets performance targets and inform future scalability improvements for multi-city deployments and predictive analytics extensions.
