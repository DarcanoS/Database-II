\section{Data System Architecture – Explanation}

% Architecture section updated according to the revised design.
% See _temp_corrections/Architecture_changes_spec.md for details.

\subsection{Architecture overview}

The Air Quality Platform adopts a simplified, layered architecture designed to meet the project's requirements without introducing unnecessary complexity. The system is organized into five main layers:

\paragraph{Clients and web frontend}
A single responsive web application serves as the primary client interface, providing tailored views for three distinct user roles: citizens seeking real-time air quality information, researchers analyzing trends and patterns, and technical administrators managing the platform's operation. This unified frontend eliminates the need for separate mobile applications or external business intelligence tools as first-class components.

\paragraph{API layer}
The platform exposes two REST-based JSON-over-HTTP endpoints. The Public REST API serves citizen and researcher requests for air quality data, historical trends, and alerts. The Admin REST API provides administrative functionality for system configuration, user management, and operational monitoring. GraphQL was intentionally excluded to maintain simplicity and reduce the learning curve for the development team.

\paragraph{Data layer}
A single PostgreSQL instance functions as both the operational and analytical data store, hosting core entities such as stations, readings, users, alerts, recommendations, and reports. The \texttt{AirQualityDailyStats} table stores pre-aggregated daily statistics to accelerate dashboard and reporting queries. A small NoSQL document store complements PostgreSQL by managing user-specific configuration data, specifically \texttt{user\_preferences} and \texttt{dashboard\_configs}, which exhibit flexible schemas unsuited to rigid relational tables.

\paragraph{Batch jobs and background processing}
Three scheduled components handle data ingestion and transformation. The Ingestion Job periodically pulls raw measurements from external air quality APIs. The Normalizer and Validator component standardizes units, normalizes timestamps, and handles missing or invalid values before storing clean readings in PostgreSQL. Finally, the Daily Aggregation Job runs once per day to populate \texttt{AirQualityDailyStats} with aggregated metrics.

\paragraph{Observability}
A single Application Logs component collects structured logs from all services—Public API, Admin API, Ingestion Job, Normalizer/Validator, and Daily Aggregation Job. This lightweight approach replaces the need for complex log ETL pipelines or dedicated observability stacks like Elasticsearch and Grafana, which exceed the scope of this academic project.

\paragraph{Recommendations}
The recommendation module provides health-related suggestions based on current pollution levels (e.g., recommending masks or limiting outdoor activities). It does not support e-commerce functionality or product sales.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\textwidth]{Imagenes/Architecture.png}
  \caption{High-level architecture of the Air Quality Platform}
  \label{fig:architecture_overview}
\end{figure}

The architecture diagram (Figure~\ref{fig:architecture_overview}) illustrates the relationships between system components. Clients interact with the web frontend, which consumes the Public or Admin REST APIs. These APIs query both PostgreSQL and the NoSQL store. Meanwhile, batch jobs operate independently to ingest and transform data, writing structured logs to the Application Logs component for operational visibility.

\subsection{Information flow and data transformations}

The platform implements a structured data pipeline that transforms raw measurements from external providers into actionable insights for end users. This flow ensures data quality, supports both real-time and historical analysis, and maintains system performance within acceptable bounds.

The pipeline begins when the Ingestion Job executes on a configurable schedule—typically every few minutes to every hour, depending on the update frequency of external air quality APIs. The job polls these endpoints and retrieves raw JSON payloads containing pollutant concentrations, timestamps, and station metadata. These payloads pass immediately to the Normalizer and Validator component, which performs critical transformations:

\begin{itemize}
  \item \textbf{Unit conversions}: Raw measurements may arrive in different units (e.g., µg/m³ vs. ppm). The normalizer standardizes all readings to a consistent unit system.
  \item \textbf{Timestamp normalization}: External APIs may use different time zones or timestamp formats. The normalizer converts all timestamps to UTC and stores them in ISO 8601 format.
  \item \textbf{Missing and invalid value handling}: Missing fields are flagged with \texttt{NULL}, while readings outside physically plausible ranges (e.g., negative concentrations) are logged and rejected.
\end{itemize}

Once validated, clean readings are inserted into the \texttt{AirQualityReading} table in PostgreSQL as individual records. This table grows at approximately 14,400 rows per day (50 stations × 3 pollutants × 96 readings per day), as detailed in the performance estimates subsection.

The Daily Aggregation Job runs once per day—typically during off-peak hours—to compute per-day, per-station, per-pollutant aggregates. These aggregates (minimum, maximum, average, and 95th percentile values) are written into the \texttt{AirQualityDailyStats} table. This analytical table accelerates dashboard and reporting queries by eliminating the need to scan millions of raw readings for time-series visualizations or historical comparisons. The aggregation job adds approximately 150 rows per day to \texttt{AirQualityDailyStats}, yielding a total of 50,000–60,000 rows over a 3-year period.

The Public and Admin REST APIs serve as the primary interface for data access. Both APIs read from PostgreSQL, selecting either raw readings (for recent, high-resolution data) or daily aggregates (for dashboards, reports, and trend analysis). The NoSQL document store provides supplementary data for personalized experiences, such as user-configured dashboard layouts and alert preferences.

Finally, the web frontend consumes these REST APIs to render views for citizens, researchers, and administrators. Citizens view real-time air quality indices and receive threshold-based alerts. Researchers query historical trends and download datasets for offline analysis. Administrators monitor system health, configure stations, and review ingestion logs.

This end-to-end pipeline directly supports the platform's non-functional requirements: sub-second query performance (NFR1) is achieved through pre-aggregation and indexing, high data quality (NFR2) is ensured by the normalization and validation layer, and efficient report generation (NFR4, NFR6) leverages the \texttt{AirQualityDailyStats} table. The decision to use a single PostgreSQL instance with automated backups satisfies fault tolerance requirements (NFR7) without necessitating distributed databases or multi-region deployments, which remain outside the scope of this academic project (NFR8).

% See _temp_corrections/Performance_Data_Estimates_spec.md
\subsection{Performance and data estimates}

This subsection provides concrete data volume and workload assumptions for the Air Quality Platform. These estimates support performance-related design decisions and align with the revised non-functional requirements, ensuring that the system remains scalable within the scope of the course project without requiring a multi-region or big-data infrastructure.

The platform's monitoring network is assumed to consist of approximately 50 stations, each tracking 3 pollutants (e.g., PM2.5, PM10, NO$_2$) with readings collected every 15 minutes. This configuration yields roughly 14,400 raw readings per day inserted into the \texttt{AirQualityReading} table. Over a 3-year operational period, the system accumulates approximately 15.8 million raw readings. In contrast, the \texttt{AirQualityDailyStats} table—which stores pre-aggregated daily statistics—grows at a much slower rate of 150 rows per day (one per station per pollutant), totaling approximately 50,000–60,000 rows over several years. The user base is estimated at around 1,000 registered accounts (\texttt{AppUser}), with 2,000–3,000 configured alerts.

Table~\ref{tab:data_estimates} summarizes the estimated volumes for the main operational entities.

\begin{table}[H]
\centering
\caption{Data volume estimates for key entities over a 3-year period}
\label{tab:data_estimates}
\begin{tabular}{|p{4cm}|p{3cm}|p{2.5cm}|p{4cm}|}
\hline
\textbf{Entity} & \textbf{Approx. volume (3 years)} & \textbf{Growth per day} & \textbf{Notes} \\
\hline
AirQualityReading & $\sim$15.8M rows & 14,400 rows & Raw sensor readings \\
\hline
AirQualityDailyStats & $\sim$50–60k rows & 150 rows & Aggregated daily statistics \\
\hline
AppUser & $\sim$1,000 users & Low & Registered user accounts \\
\hline
Alert & $\sim$2–3k alerts & Low & Threshold-based notifications \\
\hline
\end{tabular}
\end{table}

The workload exhibits a read-heavy pattern, with dashboard and analytical queries dominating system usage. Writes are moderate and predictable, consisting primarily of continuous ingestion into \texttt{AirQualityReading} and periodic batch updates to \texttt{AirQualityDailyStats}. To maintain sub-second query performance (NFR1) and support efficient report generation (NFR4, NFR6), composite indexes are applied to frequently queried columns: (\texttt{station\_id}, \texttt{datetime}) on \texttt{AirQualityReading} and (\texttt{station\_id}, \texttt{date}) on \texttt{AirQualityDailyStats}. Most dashboard and reporting queries leverage the aggregated statistics table, minimizing expensive full-table scans on the raw readings. This indexing strategy, combined with the use of a single PostgreSQL instance with automated backups, satisfies the fault tolerance requirements (NFR7) without necessitating a distributed or multi-region deployment.

Should data volumes grow significantly beyond current projections, time-based partitioning (e.g., monthly or yearly partitions on \texttt{AirQualityReading}) or read replicas can be introduced incrementally. This approach aligns with NFR8, which treats horizontal scalability as a future design goal rather than an immediate requirement, ensuring that the architecture remains extensible without overengineering for the present scope.
\newpage