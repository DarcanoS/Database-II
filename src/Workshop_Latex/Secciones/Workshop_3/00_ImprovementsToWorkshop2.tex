% Improvements to Workshop 2 summarized based on specs in _temp_corrections/.
% This section describes how we refined our previous deliverable according to instructor feedback.

\section{Improvements to Workshop 2}

Following the instructor's feedback, we revised Workshop~2 to bring the Air Quality Platform into a realistic scope for the course. The main issues identified were overly ambitious technical claims (strict real-time streaming, multi-region infrastructure, complex map-based features) and incomplete documentation of the data model, architecture, and expected workloads. We reorganized all deliverable components to address these concerns and ensure full traceability between requirements, architecture, data model, and performance assumptions.

\textbf{Requirements.} We rewrote the functional and non-functional requirements to eliminate unrealistic expectations. For FRs, we replaced strict ``real-time'' guarantees (FR1, FR4) with a \emph{periodic ingestion} model aligned with typical external API update frequencies (every few minutes or hourly). We clarified that recommendations (FR8) are simple, rule-based suggestions tied to AQI thresholds, not complex ML-driven systems, and that product suggestions (FR10) are informational health guidance, not e-commerce. Advanced features such as map-based navigation (FR11) were moved to future work, and the responsive web interface (FR13) was explicitly scoped as a web app, not native mobile apps. All requirements are now classified as baseline, optional, or future work, giving us a clear and achievable roadmap.

For NFRs, we tied performance targets to plausible workloads instead of arbitrary thresholds on massive datasets. We replaced the ``continuous 24/7 streaming'' requirement (NFR2) with automated periodic ingestion, removed the distributed big-data infrastructure claim (NFR3), and dropped multi-region redundancy (NFR7) in favour of basic fault tolerance via backups. Horizontal scalability (NFR8) is now a design goal for the future, not a mandatory multi-node deployment for the baseline.

\textbf{Architecture.} We simplified the architecture to focus on what is achievable within the course: a single responsive web app as the only client, two REST APIs (Public and Admin), a single PostgreSQL instance for both operational and analytical data, and a small NoSQL document store limited to user preferences and dashboard layouts. We removed GraphQL, external BI tools, time-series databases, Elasticsearch, Grafana, and complex log ETL pipelines from the baseline design, keeping only application logs for observability. We documented the information flow explicitly—ingest from external APIs, validate and normalize data, store raw readings in PostgreSQL, aggregate them daily into \texttt{AirQualityDailyStats}, and serve dashboards and reports via REST—and tied this flow to the batch jobs that run on a schedule.

\textbf{Data model.} We redesigned the ER diagrams and entity overview to reflect the revised schema. We renamed \texttt{User} to \texttt{AppUser} to avoid SQL reserved-word conflicts, introduced \texttt{AirQualityDailyStats} as an analytical table to support efficient historical queries, and removed JSON fields from relational tables by moving user preferences and dashboard configurations to a separate NoSQL store (\texttt{user\_preferences} and \texttt{dashboard\_configs}). Instead of a single crowded ER diagram, we now provide ER diagrams per component (Geospatial \& Monitoring, Users \& Access Control, Alerts \& Recommendations, Reporting \& Analytics) for readability. We also documented the split between operational (raw readings, users, alerts) and analytical data (daily aggregates), which is key to our performance strategy.

\textbf{Performance and data estimates.} We added concrete estimates for the expected data volumes and workloads—approximately 50 stations, 3 pollutants per station, 15-minute reading intervals yielding around 14,400 readings per day and 15.8 million rows over 3 years, plus around 1,000 registered users and typical concurrency of 20–50 active users at peak. These numbers justify the use of a single PostgreSQL instance with proper indexing and the introduction of \texttt{AirQualityDailyStats} for efficient aggregation queries. They also support our non-functional requirement targets for query performance (under 2 seconds for 95\% of requests) and report generation (under 10 seconds).

\textbf{Queries.} We updated the query examples to match the revised schema and to demonstrate the new design decisions. The SQL snippets now use \texttt{AirQualityDailyStats} for historical analysis, reference the renamed \texttt{AppUser} entity, and illustrate threshold-based alerts. We also added two NoSQL examples showing how the configuration store (\texttt{user\_preferences} and \texttt{dashboard\_configs}) is queried in practice, addressing the instructor's request for concrete NoSQL usage.

\textbf{User stories.} We rewrote all 14 user stories using the standard format (\emph{As a / I want to / so that}), adding priority (Must, Should, Could), effort estimates, and explicit acceptance criteria for each. The new user story set is aligned with the refined functional and non-functional requirements and focuses on the realistic baseline scope (data ingestion, dashboards, reports, alerts, simple recommendations, and responsive web access), while clearly marking advanced features (multi-region, complex maps) as future work.

Overall, these changes give us a more realistic, coherent baseline for the database and architecture analysis developed in Workshop~3.
